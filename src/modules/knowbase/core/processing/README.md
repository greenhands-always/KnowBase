# æ–‡ç« å¤„ç†å·¥å…·

è¿™æ˜¯ä¸€ä¸ªå·¥ç¨‹åŒ–çš„æ–‡ç« å¤„ç†ç³»ç»Ÿï¼ŒåŸºäºåŸå§‹çš„ `langchain_ner.py` æ¡ˆä¾‹å¼€å‘ï¼Œæä¾›å¯å¤ç”¨çš„å·¥å…·ç±»å’Œç»„ä»¶æ¥å¤„ç†æ–‡ç« ã€æå–æ¦‚å¿µã€åˆ†æå†…å®¹ã€‚

## ğŸš€ åŠŸèƒ½ç‰¹æ€§

- **æ¦‚å¿µæå–**: ä½¿ç”¨LLMä»æ–‡ç« ä¸­æå–æ¦‚å¿µã€å®ä½“å’Œå…³é”®è¯
- **æ–‡ç« å¤„ç†**: æ”¯æŒè´¨é‡è¯„åˆ†ã€é‡è¦æ€§è¯„åˆ†ã€åˆ†ç±»ã€æ ‡ç­¾ç”Ÿæˆç­‰
- **å¤„ç†ç®¡é“**: æµå¼å¤„ç†å¤§é‡æ–‡ç« ï¼Œæ”¯æŒæ‰¹é‡æ“ä½œ
- **ç»“æœç®¡ç†**: å¤šç§æ ¼å¼è¾“å‡ºï¼ˆJSONã€CSVã€Excelç­‰ï¼‰
- **é…ç½®ç®¡ç†**: é¢„å®šä¹‰é…ç½®æ¨¡æ¿ï¼Œæ”¯æŒè‡ªå®šä¹‰é…ç½®
- **å¯æ‰©å±•æ€§**: æ”¯æŒè‡ªå®šä¹‰å¤„ç†å™¨å’Œå¤„ç†æµç¨‹

## ğŸ“ é¡¹ç›®ç»“æ„

```
src/processing/
â”œâ”€â”€ __init__.py              # æ¨¡å—åˆå§‹åŒ–
â”œâ”€â”€ concept_extractor.py     # æ¦‚å¿µæå–å™¨
â”œâ”€â”€ article_processor.py     # æ–‡ç« å¤„ç†å™¨
â”œâ”€â”€ processing_pipeline.py   # å¤„ç†ç®¡é“
â”œâ”€â”€ result_manager.py        # ç»“æœç®¡ç†å™¨
â”œâ”€â”€ processors.py           # é¢„å®šä¹‰å¤„ç†å™¨
â”œâ”€â”€ config.py               # é…ç½®ç®¡ç†
â”œâ”€â”€ main.py                 # å‘½ä»¤è¡Œå…¥å£
â”œâ”€â”€ examples.py             # ä½¿ç”¨ç¤ºä¾‹
â””â”€â”€ README.md               # æœ¬æ–‡æ¡£
```

## ğŸ› ï¸ å®‰è£…å’Œè®¾ç½®

1. ç¡®ä¿å·²å®‰è£…å¿…è¦çš„ä¾èµ–ï¼š
```bash
pip install langchain pydantic pandas openpyxl
```

2. ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œï¼Œå¹¶å·²ä¸‹è½½zephyræ¨¡å‹ï¼š
```bash
ollama pull zephyr
```

## ğŸ“– ä½¿ç”¨æ–¹æ³•

### 1. å‘½ä»¤è¡Œä½¿ç”¨

#### åˆå§‹åŒ–é…ç½®
```bash
python src/processing/main.py init-configs
```

#### æŸ¥çœ‹å¯ç”¨é…ç½®
```bash
python src/processing/main.py list-configs
```

#### ä½¿ç”¨é¢„å®šä¹‰é…ç½®å¤„ç†
```bash
# ä½¿ç”¨æ ‡å‡†é…ç½®
python src/processing/main.py config standard

# ä½¿ç”¨è‡ªå®šä¹‰è¾“å…¥è¾“å‡ºè·¯å¾„
python src/processing/main.py config standard --input "d:/path/to/articles" --output "d:/path/to/results.json"
```

#### å¿«é€Ÿå¤„ç†
```bash
# åŸºç¡€å¤„ç†
python src/processing/main.py quick "d:/path/to/articles" --type basic

# å®Œæ•´å¤„ç†
python src/processing/main.py quick "d:/path/to/articles" --type full --output "results.json"
```

### 2. ç¼–ç¨‹æ¥å£ä½¿ç”¨

#### åŸºç¡€ä½¿ç”¨
```python
from src.processing import ConceptExtractor, ArticleProcessor, PipelineBuilder
from src.infrastructure.utils import LLMUtil

# åˆ›å»ºLLMæä¾›è€…
provider = LLMUtil.OllamaProvider(model_name="zephyr")
llm = provider.get_llm(model_name="zephyr")

# åˆ›å»ºæ¦‚å¿µæå–å™¨
concept_extractor = ConceptExtractor.create_llm_extractor(llm)

# åˆ›å»ºæ–‡ç« å¤„ç†å™¨
article_processor = ArticleProcessor.create_standard_processor(concept_extractor)

# å¤„ç†å•ç¯‡æ–‡ç« 
article_data = {
    "id": "article_1",
    "title": "AIæŠ€æœ¯å‘å±•è¶‹åŠ¿",
    "file_path": "path/to/article.md"
}

result = article_processor.process_article(article_data)
print(f"å¤„ç†ç»“æœ: {result.title}, è´¨é‡åˆ†: {result.quality_score}")
```

#### ä½¿ç”¨å¤„ç†ç®¡é“
```python
from src.processing import PipelineBuilder

# ä½¿ç”¨æ„å»ºå™¨åˆ›å»ºç®¡é“
pipeline = (PipelineBuilder()
           .with_processor(article_processor)
           .with_input_directory("d:/articles", "*.md")
           .with_output("results.json", "json")
           .with_limits(max_files=10)
           .build())

# è¿è¡Œç®¡é“
results = pipeline.run()
pipeline.print_summary()
```

#### ä½¿ç”¨é…ç½®ç®¡ç†
```python
from src.processing import ConfigManager, ConfigTemplates

# åˆ›å»ºé…ç½®ç®¡ç†å™¨
config_manager = ConfigManager()

# ä½¿ç”¨æ¨¡æ¿é…ç½®
config = ConfigTemplates.get_standard_config()
config.input_path = "d:/my/articles"
config.output_path = "d:/my/results.json"

# ä¿å­˜é…ç½®
config_manager.save_config(config, "my_config")

# åŠ è½½é…ç½®
loaded_config = config_manager.load_config("my_config")
```

#### è‡ªå®šä¹‰å¤„ç†å™¨
```python
from src.processing.processors import BASIC_PROCESSORS

def custom_ai_scorer(result):
    """è‡ªå®šä¹‰AIç›¸å…³æ€§è¯„åˆ†å™¨"""
    if result.concepts:
        ai_keywords = ['ai', 'machine learning', 'deep learning']
        all_text = ' '.join(result.concepts.concepts + result.concepts.keywords).lower()
        
        ai_score = sum(1 for keyword in ai_keywords if keyword in all_text) / len(ai_keywords)
        result.metadata['ai_relevance_score'] = ai_score
    
    return result

# åˆ›å»ºä½¿ç”¨è‡ªå®šä¹‰å¤„ç†å™¨çš„å¤„ç†å™¨
custom_processors = BASIC_PROCESSORS + [custom_ai_scorer]
article_processor = ArticleProcessor.create_custom_processor(
    concept_extractor=concept_extractor,
    processors=custom_processors
)
```

## âš™ï¸ é…ç½®é€‰é¡¹

### é¢„å®šä¹‰é…ç½®

- **basic**: åŸºç¡€é…ç½®ï¼Œåªè¿›è¡Œæ¦‚å¿µæå–
- **standard**: æ ‡å‡†é…ç½®ï¼ŒåŒ…å«å®Œæ•´å¤„ç†æµç¨‹
- **full**: å®Œæ•´é…ç½®ï¼ŒåŒ…å«æ‰€æœ‰å¤„ç†å™¨
- **analysis**: åˆ†æé…ç½®ï¼Œä¸“æ³¨äºæ·±åº¦åˆ†æ
- **batch**: æ‰¹é‡é…ç½®ï¼Œé€‚åˆå¤§é‡æ–‡ä»¶å¤„ç†
- **debug**: è°ƒè¯•é…ç½®ï¼Œç”¨äºå¼€å‘è°ƒè¯•

### é…ç½®å‚æ•°

```python
ProcessingConfig(
    # LLMé…ç½®
    llm_provider="ollama",
    llm_model="zephyr",
    llm_temperature=0.1,
    
    # è¾“å…¥é…ç½®
    input_type="directory",
    input_path="path/to/articles",
    file_pattern="*.md",
    max_files=None,
    
    # å¤„ç†é…ç½®
    processor_type="standard",
    enable_concept_extraction=True,
    enable_quality_scoring=True,
    
    # è¾“å‡ºé…ç½®
    output_path="results.json",
    output_format="json",
    save_summary_report=True,
    
    # æ€§èƒ½é…ç½®
    batch_size=10,
    enable_progress=True
)
```

## ğŸ“Š è¾“å‡ºæ ¼å¼

### å¤„ç†ç»“æœç»“æ„
```json
{
  "article_id": "article_1",
  "title": "æ–‡ç« æ ‡é¢˜",
  "status": "completed",
  "concepts": {
    "concepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2"],
    "entities": ["å®ä½“1", "å®ä½“2"],
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
    "confidence": 0.9
  },
  "quality_score": 0.85,
  "importance_score": 0.78,
  "categories": ["AI/ML", "Technology"],
  "tags": ["AI", "æŠ€æœ¯", "è¶‹åŠ¿"],
  "metadata": {
    "processing_time": 2.5,
    "file_size": 1024
  }
}
```

### æ‘˜è¦æŠ¥å‘Š
```json
{
  "total_articles": 10,
  "successful_processing": 9,
  "failed_processing": 1,
  "average_quality_score": 0.82,
  "average_importance_score": 0.75,
  "top_categories": ["AI/ML", "Technology"],
  "top_concepts": ["äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ "],
  "processing_time": 25.3
}
```

## ğŸ”§ æ‰©å±•å¼€å‘

### åˆ›å»ºè‡ªå®šä¹‰æ¦‚å¿µæå–å™¨
```python
from src.processing.concept_extractor import BaseConceptExtractor

class CustomConceptExtractor(BaseConceptExtractor):
    def extract_from_text(self, text: str) -> ConceptExtractionResult:
        # å®ç°è‡ªå®šä¹‰æå–é€»è¾‘
        pass
```

### åˆ›å»ºè‡ªå®šä¹‰å¤„ç†å™¨
```python
def custom_processor(result: ProcessingResult) -> ProcessingResult:
    # å®ç°è‡ªå®šä¹‰å¤„ç†é€»è¾‘
    result.metadata['custom_field'] = "custom_value"
    return result
```

### åˆ›å»ºè‡ªå®šä¹‰ç®¡é“
```python
from src.processing.processing_pipeline import ProcessingPipeline

class CustomPipeline(ProcessingPipeline):
    def process_batch(self, articles):
        # å®ç°è‡ªå®šä¹‰æ‰¹å¤„ç†é€»è¾‘
        pass
```

## ğŸ“ ç¤ºä¾‹

æŸ¥çœ‹ `examples.py` æ–‡ä»¶è·å–æ›´å¤šè¯¦ç»†çš„ä½¿ç”¨ç¤ºä¾‹ï¼š

```bash
python src/processing/examples.py
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **LLMè¿æ¥å¤±è´¥**
   - ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ
   - æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½ï¼š`ollama list`

2. **æ–‡ä»¶è·¯å¾„é”™è¯¯**
   - ä½¿ç”¨ç»å¯¹è·¯å¾„
   - ç¡®ä¿æ–‡ä»¶å­˜åœ¨ä¸”å¯è¯»

3. **å†…å­˜ä¸è¶³**
   - å‡å°‘batch_size
   - é™åˆ¶max_filesæ•°é‡

4. **å¤„ç†é€Ÿåº¦æ…¢**
   - å¯ç”¨å¹¶è¡Œå¤„ç†
   - ä½¿ç”¨æ›´å¿«çš„LLMæ¨¡å‹

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªMITè®¸å¯è¯ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªå·¥å…·ï¼